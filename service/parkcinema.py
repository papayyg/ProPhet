import aiohttp
from bs4 import BeautifulSoup


async def parse_parkcinema():
    output_film = []
    async with aiohttp.ClientSession() as session:
        url = "https://parkcinema.az/?lang=ru"
        async with session.get(url) as response:
            soup = BeautifulSoup(await response.text(encoding='latin-1'), "html.parser")

            for item in soup.select("#frontpage-movies > div[rel=today] > .normal > .m-item"):
                details = item.find('div', class_='m-i-details')
                title = details.find('a', class_='m-i-d-title').text
                bytes_title = bytes(title, 'latin-1')
                title = bytes_title.decode('utf-8')
                temp  = f"https://parkcinema.az{details.find('a', class_='m-i-d-title').get('href')}?lang=ru"
                if not temp.startswith('https://parkcinema.az/movies/'):
                    continue
                link = f"https://mobile.parkcinema.az{details.find('a', class_='m-i-d-title').get('href')}?lang=ru"
                date  = details.find('div', class_='m-i-d-date').text
                bytes_date = bytes(date, 'latin-1')
                date = bytes_date.decode('utf-8')
                type  = details.find('div', class_='m-i-d-type').text
                lang  = ' '.join([span.text for span in details.find('div', class_='m-i-d-lang').find_all('span')])
                age  = details.find('div', class_='m-i-d-age').text
                media  = bytes(item.find('div', class_='m-i-left').find('img').get("src"), 'latin-1') .decode('utf-8')

                async with session.get(temp) as response:
                    soup = BeautifulSoup(await response.text(), 'html.parser')

                    country = soup.find("label", string="–°—Ç—Ä–∞–Ω–∞:").find_next_sibling().text.strip()
                    year = soup.find("label", string="–ì–æ–¥").find_next_sibling().text.strip()
                    director = soup.find("label", string="–†–µ–∂–∏—Å—Å–µ—Ä").find_next_sibling().text.strip()
                    genre = soup.find("label", string="–ñ–∞–Ω—Ä").find_next_sibling().text.strip()
                    cast = soup.find("label", string="–í —Ä–æ–ª—è—Ö").find_next_sibling().text.strip().replace("\n", ", ")
                    duration = soup.find("label", string="–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å").find_next_sibling().text.strip()

                    temp = ''
                    if 'RU' in lang:
                        temp += 'üá∑üá∫ '
                    if 'EN' in lang:
                        temp += 'üá∫üá∏ '
                    if 'TR' in lang:
                        temp += 'üáπüá∑ '
                    if 'AZ' in lang:
                        temp += 'üá¶üáø '

                    output_film.append([f'<i><b>{title} ({year})</b></i>\n'
                    f'<b>–í –∫–∏–Ω–æ—Ç–µ–∞—Ç—Ä–µ:</b> <i>{date}</i>\n'
                    f'<b>–°—Ç—Ä–∞–Ω–∞:</b> <i>{country}</i>\n'
                    f'<b>–§–æ—Ä–º–∞—Ç—ã:</b> {temp}<i>{type}</i>\n'
                    f'üß© <b>–ñ–∞–Ω—Ä:</b> <i>{genre}</i>\n'
                    f'\U0001F3A5 <b>–†–µ–∂–∏—Å—Å–µ—Ä:</b> <i>{director}</i>\n'
                    f'\U0001F64D <b>–í —Ä–æ–ª—è—Ö:</b> <i>{cast}</i>\n'
                    f'\U0001F39E <b>–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:</b> <i>{duration}</i>\n'
                    f'\U0001F51E <b>–í–æ–∑—Ä–∞—Å—Ç–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:</b> <i>{age}</i>', media, link])
    return output_film